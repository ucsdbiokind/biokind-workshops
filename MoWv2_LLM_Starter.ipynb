{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Biokind@UCSD X Meals On Wheels San Diego County Project 2 - LLMs Component"
      ],
      "metadata": {
        "id": "aI1NqP86mUw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install openai==0.28 --quiet"
      ],
      "metadata": {
        "id": "pMmbQzV_mU4G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import IPython\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# API Configuration\n",
        "openai.api_key ="
      ],
      "metadata": {
        "id": "bWYw3bEOmwAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# basic API call structure\n",
        "\n",
        "res = openai.ChatCompletion.create(\n",
        "    model = \"gpt-4o\",   # OpenAI model (gpt-4o, gpt-3.5-turbo)\n",
        "    messages = [\n",
        "        {\"role\": \"user\",\n",
        "         \"content\": \"Who's Biokind Analytics at UC San Diego?\"\n",
        "         }\n",
        "        ],\n",
        "    temperature = 0,   # how creative you want the responses to be\n",
        "    max_tokens = 100   # how long you want the responses to be (consider latency)\n",
        ")"
      ],
      "metadata": {
        "id": "p7Cyp4ZjmwJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# res"
      ],
      "metadata": {
        "id": "PuSYmEYcp-jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(res.choices[0].message['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkuPHJ6Wouqn",
        "outputId": "70a484ea-3a48-4a35-f1f0-d5209229e3f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As of my last update in October 2023, there is no widely known entity or group specifically named \"Biokind Analytics\" at UC San Diego. It's possible that Biokind Analytics could be a newly established research group, startup, or project that has emerged after my last update, or it could be a smaller, less publicized initiative within the university.\n",
            "\n",
            "UC San Diego is a major research university with numerous departments, research groups, and startups, particularly in fields related to biotechnology, data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ReAct Framework - combining LLMs with external tools (e.g., search API) to generate informed responses"
      ],
      "metadata": {
        "id": "1mijeDfWsITg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install langchain google-search-results chromadb tiktoken --quiet"
      ],
      "metadata": {
        "id": "46QBazoLxDsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install langchain-community"
      ],
      "metadata": {
        "id": "a1Mag5igsiZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentType\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "# LangChain Configuration\n",
        "os.environ['OPENAI_API_KEY'] = openai.api_key\n",
        "os.environ['SERPAPI_API_KEY'] ="
      ],
      "metadata": {
        "id": "-12nD8Owsj6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo with SerpAPI\n",
        "\n",
        "# model initiation\n",
        "model = OpenAI(temperature=0)\n",
        "\n",
        "# SerpAPI tools\n",
        "tools = load_tools(['serpapi', 'llm-math'], llm=model)   # processing pipeline\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    model,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        "    )   # your pipeline executor"
      ],
      "metadata": {
        "id": "zisk52A9pxnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3de0930-3d0f-48ec-b3f9-ba69020fa011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let the agent do the research!\n",
        "res = agent.run(\"Who's Biokind Analytics at UC San Diego? A student organization at UC San Diego\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IAvpG-9xXkS",
        "outputId": "814f2174-0a64-46db-d31a-78fd74266f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the search engine to find information about Biokind Analytics at UC San Diego.\n",
            "Action: Search\n",
            "Action Input: \"Biokind Analytics UC San Diego\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m['Simultaneously, facilitates opportunities for UC San Diego students to positively apply their learning to their own community in impactful, real ...', 'Meet our UCSD Biokind Analytics team for the spring 2023 semester!', 'Through Biokind, Phu hopes to utilize his studies at UCSD in helping healthcare nonprofits effectively extract insights from data to improve operations and ...', \"San Diego, California ... OAK's mission is to provide resources and support for kids battling cancer and their siblings, through camps, family-oriented events, ...\", 'The “University of California San Diego” is hereby referred to as “UC San Diego” for the purposes of this Constitution. 2. “Biokind at UC ...', 'Meet our UC San Diego Biokind Analytics team for 2023 Spring! Our team at UC San Diego worked with Curebound, a non-profit with the mission ...', \"UCSD Fall 2023 Teams. Meet our University of California San Diego Biokind Analytics team for the fall 2023 semester! Team Mama's Kitchen x Biokind (v1) ...\", 'Biokind Analytics is an international 501(c)(3) organization that provides data analysis in the healthcare non-profit sector. Today, even small businesses ...', 'Sophomore at the UC San Diego studying Math-Economics and Data Science. ... Lucien is studying math, economics, and data science at the University of California ...', 'Biokind at UC San Diego. Biokind at UC San Diego. Meet the Board! Impact Report · Biokind Analytics Website.']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should read through the search results to find information about Biokind Analytics at UC San Diego.\n",
            "Action: Search\n",
            "Action Input: \"Biokind Analytics UC San Diego\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m['Simultaneously, facilitates opportunities for UC San Diego students to positively apply their learning to their own community in impactful, real ...', 'Meet our UCSD Biokind Analytics team for the spring 2023 semester!', 'Through Biokind, Phu hopes to utilize his studies at UCSD in helping healthcare nonprofits effectively extract insights from data to improve operations and ...', \"San Diego, California ... OAK's mission is to provide resources and support for kids battling cancer and their siblings, through camps, family-oriented events, ...\", 'The “University of California San Diego” is hereby referred to as “UC San Diego” for the purposes of this Constitution. 2. “Biokind at UC ...', 'Meet our UC San Diego Biokind Analytics team for 2023 Spring! Our team at UC San Diego worked with Curebound, a non-profit with the mission ...', \"UCSD Fall 2023 Teams. Meet our University of California San Diego Biokind Analytics team for the fall 2023 semester! Team Mama's Kitchen x Biokind (v1) ...\", 'Biokind Analytics is an international 501(c)(3) organization that provides data analysis in the healthcare non-profit sector. Today, even small businesses ...', 'Sophomore at the UC San Diego studying Math-Economics and Data Science. ... Lucien is studying math, economics, and data science at the University of California ...', 'Biokind at UC San Diego. Biokind at UC San Diego. Meet the Board! Impact Report · Biokind Analytics Website.']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should visit the Biokind Analytics website to learn more about the organization.\n",
            "Action: Search\n",
            "Action Input: \"Biokind Analytics UC San Diego website\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m['Simultaneously, facilitates opportunities for UC San Diego students to positively apply their learning to their own community in impactful, real ...', 'We analyze patient and client demographics including ethnicity, race, socioeconomic status, education level, and other relevant factors. Often times, ...', \"San Diego, California ... OAK's mission is to provide resources and support for kids battling cancer and their siblings, through camps, family-oriented events, ...\", 'Biokind at UC San Diego. Biokind at UC San Diego. Meet the Board! Impact Report · Biokind Analytics Website.', 'Meet our UCSD Biokind Analytics team for the spring 2023 semester!', 'Meet our UC San Diego Biokind Analytics team for 2023 Spring! Our team at UC San Diego worked with Curebound, a non-profit with the mission ...', \"Biokind Analytics at UC San Diego · Biological Sciences Student Association · Biology Undergraduate and Master's Mentorship Program · Biomedical Engineering ...\", 'Biokind Analytics is an international 501(c)(3) organization that provides data analysis in the healthcare non-profit sector. Today, even small businesses ...', 'Phu Dang. Director at UC San Diego. Phu is studying data science and real estate development at the University of California San Diego. He is from the San ...', 'Founded by the pair last year, Biokind Analytics is a 501(c)(3) non-profit based in Houston, with chapters at seven other American universities, ...']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should read through the information on the Biokind Analytics website to learn more about the organization at UC San Diego.\n",
            "Action: Search\n",
            "Action Input: \"Biokind Analytics UC San Diego website\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m['Simultaneously, facilitates opportunities for UC San Diego students to positively apply their learning to their own community in impactful, real ...', 'We analyze patient and client demographics including ethnicity, race, socioeconomic status, education level, and other relevant factors. Often times, ...', \"San Diego, California ... OAK's mission is to provide resources and support for kids battling cancer and their siblings, through camps, family-oriented events, ...\", 'Biokind at UC San Diego. Biokind at UC San Diego. Meet the Board! Impact Report · Biokind Analytics Website.', 'Meet our UCSD Biokind Analytics team for the spring 2023 semester!', 'Meet our UC San Diego Biokind Analytics team for 2023 Spring! Our team at UC San Diego worked with Curebound, a non-profit with the mission ...', \"Biokind Analytics at UC San Diego · Biological Sciences Student Association · Biology Undergraduate and Master's Mentorship Program · Biomedical Engineering ...\", 'Biokind Analytics is an international 501(c)(3) organization that provides data analysis in the healthcare non-profit sector. Today, even small businesses ...', 'Phu Dang. Director at UC San Diego. Phu is studying data science and real estate development at the University of California San Diego. He is from the San ...', 'Founded by the pair last year, Biokind Analytics is a 501(c)(3) non-profit based in Houston, with chapters at seven other American universities, ...']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: Biokind Analytics is a student organization at UC San Diego that provides data analysis for healthcare non-profits. It was founded by Phu Dang and Lucien Chen in 2020.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8W9auqb9xYAh",
        "outputId": "10a9fede-1573-474a-eb82-4394049fceb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Biokind Analytics is a student organization at UC San Diego that provides data analysis for healthcare non-profits. It was founded by Phu Dang and Lucien Chen in 2020.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7FqFlIg7EoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extra definitions on \"tools\" and \"agent\" within the LangChain workflow:**\n",
        "\n",
        "**Tools** - Individual components that perform specific tasks, such as retrieving information from external sources or processing data. Tools can be methods or classes that allow agents to interact with their environment. For example, tools can interact with a Stock Market index over an API, update a Google Calendar event, or run a query against a database. The LangChain library provides a selection of prebuilt tools, but in some cases, existing tools may need to be modified or new ones built.\n",
        "\n",
        "**Agents** - Use a language model (LLM) as a reasoning engine to determine which actions to take and in which order. Agents also involve making decisions about which actions to take, taking those actions, observing the results, and repeating the process until a desired outcome is achieved. Agents have an Executor level where they look at the inputs and decide what is the best tool based on what has been initialized for the bot."
      ],
      "metadata": {
        "id": "wba5dkZF7AIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Back to OpenAI - A More Structured Approach"
      ],
      "metadata": {
        "id": "cgB-M8-7zLBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API calls as a function\n",
        "\n",
        "def get_response(\n",
        "    messages,\n",
        "    model='gpt-4o',\n",
        "    temperature=0,\n",
        "    max_tokens=300\n",
        "):\n",
        "  res = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=messages,\n",
        "      temperature=temperature,\n",
        "      max_tokens=max_tokens,\n",
        "  )\n",
        "  return res.choices[0].message['content']"
      ],
      "metadata": {
        "id": "gxEkrgt_yYoC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_trending_movies = [\n",
        "    \"The Suicide Squad\",\n",
        "    \"No Time to Die\",\n",
        "    \"Dune\",\n",
        "    \"Spider-Man: No Way Home\",\n",
        "    \"The French Dispatch\",\n",
        "    \"Black Widow\",\n",
        "    \"Eternals\",\n",
        "    \"The Matrix Resurrections\",\n",
        "    \"West Side Story\",\n",
        "    \"The Many Saints of Newark\"\n",
        "    ]\n",
        "\n",
        "system_message = \"\"\"\n",
        "Your task is to recommend movies to a customer.\n",
        "\n",
        "You are responsible to recommend a movie from the top global trending movies from {global_trending_movies}.\n",
        "\n",
        "You should refrain from asking users for their preferences and avoid asking for personal information.\n",
        "\n",
        "If you don't know the user interests, you should respond \"Sorry, couldn't find a movie to recommend today.\".\n",
        "\"\"\"\n",
        "\n",
        "request = \"\"\"\n",
        "Please recommend a movie based on my interests. Thanks!\n",
        "\"\"\"\n",
        "\n",
        "message = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_message.format(global_trending_movies=global_trending_movies)\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": request\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_response(message)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW33PrTEyY3E",
        "outputId": "3e165f91-6bc6-4b8e-81a6-9eebd36543d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorry, couldn't find a movie to recommend today.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frame = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_message.format(global_trending_movies=global_trending_movies)\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "def generate_request(frame, edit_index, request):\n",
        "  frame[edit_index]['content'] = request\n",
        "  return frame\n",
        "\n",
        "new_request = \"\"\"\n",
        "I love super-hero movies. Please recommend a movie based on my interests.\n",
        "\"\"\"\n",
        "\n",
        "msg_with_interest = generate_request(frame, 1, new_request)\n",
        "response = get_response(msg_with_interest)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5w5TxgqyZT_",
        "outputId": "6623aa88-8675-4dd0-8382-a8c1eb9049f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I recommend \"The Suicide Squad\" or \"Spider-Man: No Way Home.\" Both are fantastic superhero movies that you might enjoy!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Add Delimiters - helps to better structure instructions and the overall prompt components, leading to more reliable responses"
      ],
      "metadata": {
        "id": "-oeJjC0p4Tqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Convert the following code block in the #### <code> #### section to Python:\n",
        "\n",
        "####\n",
        "strings2.push(\"one\")\n",
        "strings2.push(\"two\")\n",
        "strings2.push(\"THREE\")\n",
        "strings2.push(\"4\")\n",
        "####\n",
        "\"\"\"\n",
        "\n",
        "message = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "IPython.display.Markdown(\"```python\" + get_response(message) + \"\\n```\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "yBwK9S0U4LnT",
        "outputId": "442977f3-0524-4fbb-a925-5266fe93f453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```pythonCertainly! Here is the equivalent Python code for the given code block:\n\n```python\nstrings2 = []\nstrings2.append(\"one\")\nstrings2.append(\"two\")\nstrings2.append(\"THREE\")\nstrings2.append(\"4\")\n```\n\nIn Python, the `append` method is used to add elements to the end of a list, which is similar to the `push` method in some other programming languages.\n```"
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Think Step by Step - to elicit reasoning in LLMs. Prompting in step-by-step allows the model to provide the detailed steps before providing a final response"
      ],
      "metadata": {
        "id": "ZhQBWuLP47ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
        "\n",
        "Solve by breaking the problem into steps. First, identify the odd numbers, add them, and indicate whether the result is odd or even.\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response= get_response(messages)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71sQB7Qi4si2",
        "outputId": "50a91fd4-02d4-4ed6-91dc-c135615171e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To solve the problem, we need to follow these steps:\n",
            "\n",
            "1. Identify the odd numbers in the group.\n",
            "2. Add the identified odd numbers.\n",
            "3. Determine whether the sum is odd or even.\n",
            "\n",
            "### Step 1: Identify the odd numbers\n",
            "The given numbers are: 15, 32, 5, 13, 82, 7, 1.\n",
            "\n",
            "- 15 is odd.\n",
            "- 32 is even.\n",
            "- 5 is odd.\n",
            "- 13 is odd.\n",
            "- 82 is even.\n",
            "- 7 is odd.\n",
            "- 1 is odd.\n",
            "\n",
            "The odd numbers are: 15, 5, 13, 7, 1.\n",
            "\n",
            "### Step 2: Add the identified odd numbers\n",
            "Now, we add the odd numbers together:\n",
            "\n",
            "15 + 5 + 13 + 7 + 1\n",
            "\n",
            "Let's break it down step by step:\n",
            "\n",
            "- 15 + 5 = 20\n",
            "- 20 + 13 = 33\n",
            "- 33 + 7 = 40\n",
            "- 40 + 1 = 41\n",
            "\n",
            "So, the sum of the odd numbers is 41.\n",
            "\n",
            "### Step 3: Determine whether the sum is odd or even\n",
            "41 is an odd number.\n",
            "\n",
            "Therefore, the sum of the odd numbers in this group is 41, which is odd. The statement that the odd numbers in this group add up to an even number is incorrect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Role Playing - define context for appropriate responses given certain situations/dynamics (e.g., healthcare non-profit)"
      ],
      "metadata": {
        "id": "ci353Ecg5U32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"\n",
        "The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\n",
        "\"\"\"\n",
        "\n",
        "user_message_1 = \"\"\"\n",
        "Hello, who are you?\n",
        "\"\"\"\n",
        "\n",
        "ai_message_1 = \"\"\"\n",
        "Greeting! I am an AI research assistant. How can I help you today?\n",
        "\"\"\"\n",
        "\n",
        "prompt = \"\"\"\n",
        "Human: Can you tell me about the creation of blackholes? Please keep it concise\n",
        "AI:\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_message\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": user_message_1\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": ai_message_1\n",
        "\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_response(messages, temperature=1.5, max_tokens=50)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-6Uuzzx5UYd",
        "outputId": "e0df3140-c68e-4d07-d4c7-8f60a8ed8723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Certainly! Black holes are formed from the gravitational collapse of massive stars. When a star with sufficient mass exhausts its nuclear fuel, it can no longer counteract its own gravity. Depending(Opens Fire him mate.equalsFace camouflageBold.history.Work almost\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some ideas for our project\n",
        "\n",
        "# system_message = \"\"\"\n",
        "# The following is a conversation with the Director of Philanthropy from a\n",
        "# non-profit delivering healthy meals for San Diegans in need, such as seniors,\n",
        "# veterans, disabled folks. ...\n",
        "# OR\n",
        "# Assume you are the Director of Philanthropy from a non-profit...\n",
        "# \"\"\""
      ],
      "metadata": {
        "id": "EuXi3CRR9EYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extra notes on roles within the OpenAI framwork:**\n",
        "\n",
        "Source: https://community.make.com/t/what-is-the-difference-between-system-user-and-assistant-roles-in-chatgpt/36160/4\n",
        "\n",
        "**System Role** - The System role is used to provide setup information or context that informs the behavior of the model. This can include instructions or guidelines on how the conversation should proceed.\n",
        "\n",
        "**User Role** - This role represents the human user in the conversation. Inputs from the user guide the conversation and prompt responses from the assistant.\n",
        "\n",
        "**Assistant Role** - This is the role of the model itself, responding to user inputs based on the context set by the system."
      ],
      "metadata": {
        "id": "_EgB50Zp7HLk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hve8sfX87w9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Advanced Prompt Engineering"
      ],
      "metadata": {
        "id": "i-YS6dx5_Q1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Few-shot In-Context Learning"
      ],
      "metadata": {
        "id": "YVrvrmtD_UUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Your task is to classify an input text (delimited by ```) as either offensive or non-offensive.\n",
        "\n",
        "Use the following examples to help with steering your responses:\n",
        "\n",
        "Text: I love you\n",
        "Output: non-offensive\n",
        "\n",
        "Text: I dislike all those people working at the company\n",
        "Output: offensive\n",
        "\n",
        "Text: I think this feature is not ideal\n",
        "Output: non-offensive\n",
        "\n",
        "Text: Those people are so stupid\n",
        "Output: offensive\n",
        "\n",
        "Text: {user_input}\n",
        "Output:\n",
        "\"\"\"\n",
        "\n",
        "message = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt.format(\n",
        "            user_input=\"```I respectfully disagree with your opinion.```\"\n",
        "        )\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_response(message)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5nG-YU8_S9H",
        "outputId": "22ff887d-5c77-46ae-f494-aa60e40b944a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "non-offensive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_req = prompt.format(\n",
        "            user_input=\"```Your opinion sucks.```\"\n",
        "        )\n",
        "\n",
        "new_req = generate_request(message, 0, new_req)\n",
        "\n",
        "response = get_response(new_req)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZly62rO_jsx",
        "outputId": "0c4be69d-7a9e-41a2-941e-a5dd3e08b29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: offensive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chain-of-Thought (CoT) Prompting - list the steps the model should perform, building on the step-by-step idea earlier"
      ],
      "metadata": {
        "id": "sUzxikGtAT3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies = \"\"\"\n",
        "The Enigma Code\n",
        "Category: Historical Drama\n",
        "Rating: 8.3/10\n",
        "Description: Set during World War II, this gripping historical drama follows the life of Alan Turing, a brilliant mathematician tasked with cracking the Enigma code used by the Nazis. His efforts contribute significantly to the Allies' victory.\n",
        "Actors: Benedict Cumberbatch, Keira Knightley, Matthew Goode\n",
        "Language: English\n",
        "Release Date: March 15, 2014\n",
        "Award Winner: Academy Award for Best Adapted Screenplay\n",
        "\n",
        "Shadows of the Samurai\n",
        "Category: Action/Adventure\n",
        "Rating: 7.9/10\n",
        "Description: In feudal Japan, a skilled samurai seeks vengeance against the corrupt warlord who murdered his master. With his swordsmanship and determination, he embarks on a dangerous journey to restore justice.\n",
        "Actors: Ken Watanabe, Tadanobu Asano, Rinko Kikuchi\n",
        "Language: Japanese\n",
        "Release Date: November 7, 2017\n",
        "Award Winner: None\n",
        "\n",
        "Mind Games\n",
        "Category: Psychological Thriller\n",
        "Rating: 8.1/10\n",
        "Description: A renowned psychologist becomes entangled in a twisted game of cat and mouse with a patient who harbors dark secrets. As their sessions progress, the lines between reality and deception blur, leading to a mind-bending climax.\n",
        "Actors: Leonardo DiCaprio, Natalie Portman, Michael Fassbender\n",
        "Language: English\n",
        "Release Date: August 22, 2019\n",
        "Award Winner: None\n",
        "\n",
        "La Casa del Tango\n",
        "Category: Musical/Drama\n",
        "Rating: 8.7/10\n",
        "Description: In the vibrant world of Buenos Aires, a passionate tango dancer finds love and inspiration amidst the backdrop of political unrest. This musical drama explores the power of dance and the pursuit of dreams.\n",
        "Actors: Antonio Banderas, Penélope Cruz, Javier Bardem\n",
        "Language: Spanish\n",
        "Release Date: June 5, 2020\n",
        "Award Winner: Golden Globe for Best Foreign Language Film\n",
        "\n",
        "Timeless Love\n",
        "Category: Romance/Fantasy\n",
        "Rating: 7.5/10\n",
        "Description: A magical encounter transports a modern-day writer back in time to Victorian England, where she falls in love with a charming aristocrat. As they navigate the complexities of time, their love is put to the ultimate test.\n",
        "Actors: Rachel McAdams, Tom Hiddleston, Emma Thompson\n",
        "Language: English\n",
        "Release Date: February 14, 2022\n",
        "Award Winner: None\n",
        "\n",
        "The Pursuit of Justice\n",
        "Category: Legal Drama\n",
        "Rating: 8.4/10\n",
        "Description: Inspired by true events, this gripping legal drama follows a determined lawyer's fight against a powerful pharmaceutical company responsible for a life-threatening drug. The courtroom battle becomes a quest for justice and redemption.\n",
        "Actors: Denzel Washington, Viola Davis, Michael B. Jordan\n",
        "Language: English\n",
        "Release Date: October 10, 2022\n",
        "Award Winner: None\n",
        "\n",
        "The Forgotten Island\n",
        "Category: Adventure/Mystery\n",
        "Rating: 7.6/10\n",
        "Description: A group of explorers stumbles upon a mysterious island believed to be uninhabited. As they uncover the island's secrets, they encounter deadly challenges and unravel an ancient civilization's enigma.\n",
        "Actors: Chris Pratt, Bryce Dallas Howard, Tom Holland\n",
        "Language: English\n",
        "Release Date: July 2, 2023\n",
        "Award Winner: None\n",
        "\n",
        "The Silent Witness\n",
        "Category: Crime/Thriller\n",
        "Rating: 8.2/10\n",
        "Description: A talented forensic pathologist becomes entangled in a high-stakes murder investigation when she discovers crucial evidence that points to a powerful criminal network. With her life on the line, she must outsmart the perpetrators.\n",
        "Actors: Emily Blunt, Jake Gyllenhaal, Mark Ruffalo\n",
        "Language: English\n",
        "Release Date: November 18, 2023\n",
        "Award Winner: None\n",
        "\n",
        "A Tale of Two Worlds\n",
        "Category: Fantasy/Adventure\n",
        "Rating: 7.8/10\n",
        "Description: When a young orphan discovers a magical portal to a parallel universe, she embarks on a thrilling adventure to save both realms from an impending disaster. Along the way, she learns about the power of friendship and self-belief.\n",
        "Actors: Millie Bobby Brown, Tom Holland, Helena Bonham Carter\n",
        "Language: English\n",
        "Release Date: April 5, 2024\n",
        "Award Winner: None\n",
        "\n",
        "A Symphony of Souls\n",
        "Category: Music/Drama\n",
        "Rating: 9.0/10\n",
        "Description: Set against the backdrop of a renowned symphony orchestra, this emotionally charged drama explores the lives and intertwining stories of its members. Through the power of music, they find solace, love, and redemption.\n",
        "Actors: Meryl Streep, Tom Hanks, Cate Blanchett\n",
        "Language: English\n",
        "Release Date: December 25, 2024\n",
        "Award Winner: None\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4vxQBiWOAFBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"\n",
        "You task is to make movie recommendations based on a user request (delimited by ```).\n",
        "\n",
        "Step 1: Check if the user is asking about movies. If the user is not asking about movies, just respond \"Please ask something about movies!\".\n",
        "\n",
        "Step 2: If the user is asking for a movie recommendation, check if they have any specific requests or interests.\n",
        "\n",
        "Step 3: Check if there are any movie/s we can recommend from the following: {movies}\n",
        "\n",
        "Step 4: Prepare a response to the user with the movie recommendation/s. The recommendation have to be about movies that are available in the list above. The response needs to have a friendly and helpful tone.\n",
        "\n",
        "Return a response with the following reasoning steps and final output to the user:\n",
        "\n",
        "Step 1: <Step 1 reasoning>\n",
        "\n",
        "Step 2: <Step 2 reasoning>\n",
        "\n",
        "Step 3: <Step 3 reasoning>\n",
        "\n",
        "Step 4: <final response>\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_message.format(movies=movies)\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"```Do you have any drama movies?```\"\n",
        "    }\n",
        "]\n",
        "\n",
        "movie_rec = get_response(messages, temperature=0, max_tokens=500)\n",
        "\n",
        "print(movie_rec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VunIbcl4AjBW",
        "outputId": "2465709a-800d-4b5d-f31e-025ed95cb000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: The user is asking about movies, specifically drama movies.\n",
            "\n",
            "Step 2: The user has a specific interest in drama movies.\n",
            "\n",
            "Step 3: From the list provided, there are several drama movies available:\n",
            "- The Enigma Code (Historical Drama)\n",
            "- La Casa del Tango (Musical/Drama)\n",
            "- The Pursuit of Justice (Legal Drama)\n",
            "- A Symphony of Souls (Music/Drama)\n",
            "\n",
            "Step 4: \n",
            "Sure! Here are some drama movies you might enjoy:\n",
            "\n",
            "1. **The Enigma Code**\n",
            "   - **Category:** Historical Drama\n",
            "   - **Rating:** 8.3/10\n",
            "   - **Description:** Set during World War II, this gripping historical drama follows the life of Alan Turing, a brilliant mathematician tasked with cracking the Enigma code used by the Nazis. His efforts contribute significantly to the Allies' victory.\n",
            "   - **Actors:** Benedict Cumberbatch, Keira Knightley, Matthew Goode\n",
            "   - **Language:** English\n",
            "   - **Release Date:** March 15, 2014\n",
            "   - **Award Winner:** Academy Award for Best Adapted Screenplay\n",
            "\n",
            "2. **La Casa del Tango**\n",
            "   - **Category:** Musical/Drama\n",
            "   - **Rating:** 8.7/10\n",
            "   - **Description:** In the vibrant world of Buenos Aires, a passionate tango dancer finds love and inspiration amidst the backdrop of political unrest. This musical drama explores the power of dance and the pursuit of dreams.\n",
            "   - **Actors:** Antonio Banderas, Penélope Cruz, Javier Bardem\n",
            "   - **Language:** Spanish\n",
            "   - **Release Date:** June 5, 2020\n",
            "   - **Award Winner:** Golden Globe for Best Foreign Language Film\n",
            "\n",
            "3. **The Pursuit of Justice**\n",
            "   - **Category:** Legal Drama\n",
            "   - **Rating:** 8.4/10\n",
            "   - **Description:** Inspired by true events, this gripping legal drama follows a determined lawyer's fight against a powerful pharmaceutical company responsible for a life-threatening drug. The courtroom battle becomes a quest for justice and redemption.\n",
            "   - **Actors:** Denzel Washington, Viola Davis, Michael B. Jordan\n",
            "   - **Language:** English\n",
            "   - **Release Date:** October 10, 2022\n",
            "   - **Award Winner:** None\n",
            "\n",
            "4. **A Symphony of Souls**\n",
            "   - **Category:** Music/Drama\n",
            "   - **Rating:** 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prompt Chaining - combine separate prompts, providing another response as part of another prompt to achieve a goal"
      ],
      "metadata": {
        "id": "M8Mom1qeBl8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt 1: step by step reasoning (provided above)\n",
        "# Prompt 2: extract only the final response we will send to the user\n",
        "\n",
        "system_message_2 = \"\"\"\n",
        "You will be given a list of steps that a model has responded with. Your task is\n",
        "to extract only the full response in Step 4 from the following text: {movie_recommendation_response}\n",
        "\n",
        "Step 4:\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_message_2.format(\n",
        "            movie_recommendation_response=movie_rec)\n",
        "    }\n",
        "]\n",
        "\n",
        "final_response = get_response(messages, temperature=0)\n",
        "\n",
        "print(final_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAd3ClL4BXqB",
        "outputId": "5ed9a7f9-078d-43a3-804a-0dfd86e70c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Here are some drama movies you might enjoy:\n",
            "\n",
            "1. **The Enigma Code**\n",
            "   - **Category:** Historical Drama\n",
            "   - **Rating:** 8.3/10\n",
            "   - **Description:** Set during World War II, this gripping historical drama follows the life of Alan Turing, a brilliant mathematician tasked with cracking the Enigma code used by the Nazis. His efforts contribute significantly to the Allies' victory.\n",
            "   - **Actors:** Benedict Cumberbatch, Keira Knightley, Matthew Goode\n",
            "   - **Language:** English\n",
            "   - **Release Date:** March 15, 2014\n",
            "   - **Award Winner:** Academy Award for Best Adapted Screenplay\n",
            "\n",
            "2. **La Casa del Tango**\n",
            "   - **Category:** Musical/Drama\n",
            "   - **Rating:** 8.7/10\n",
            "   - **Description:** In the vibrant world of Buenos Aires, a passionate tango dancer finds love and inspiration amidst the backdrop of political unrest. This musical drama explores the power of dance and the pursuit of dreams.\n",
            "   - **Actors:** Antonio Banderas, Penélope Cruz, Javier Bardem\n",
            "   - **Language:** Spanish\n",
            "   - **Release Date:** June 5, 2020\n",
            "   - **Award Winner:** Golden Globe for Best Foreign Language Film\n",
            "\n",
            "3. **The Pursuit of Justice**\n",
            "   - **Category:** Legal Drama\n",
            "   - **Rating:** 8.4/10\n",
            "   - **\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Retrieval-Augmented Generation - enhance the responses of LLMs by accessing knowledgeable sources\n",
        "\n",
        "**Gemini's take**: Retrieval Augmented Generation (RAG) is a model that combines a pre-trained language model with a retriever module to pull relevant data from external sources. This allows RAG to produce responses that are influenced by a wider range of knowledge than the model's parameters alone."
      ],
      "metadata": {
        "id": "IbrKB0dTCP1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores.elastic_vector_search import ElasticVectorSearch\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.prompts import PromptTemplate\n",
        "import urllib\n",
        "\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "# from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "qf6TG1T9CCDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data from GitHub\n",
        "f = urllib.request.urlopen(\"https://raw.githubusercontent.com/comet-ml/comet-llmops/main/data/kar-gpt.txt\")\n",
        "text_data = f.read().decode(\"utf-8\")\n",
        "\n",
        "# split text into chunks\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separator=\" \")\n",
        "texts = text_splitter.split_text(text_data)\n",
        "\n",
        "# initialize embeddings from OpenAI\n",
        "embeddings = OpenAIEmbeddings()   # CohereEmbeddings"
      ],
      "metadata": {
        "id": "hN83LzVcEhrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dafd5a4-95ec-42bb-fb7d-749f18702188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "okxCTn30ENzu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store the embeddings into ChromaDB, a dedicated vector storage. We then perform\n",
        "# a search by querying Chroma\n",
        "\n",
        "docsearch = Chroma.from_texts(texts, embeddings, metadatas=[{\"source\": str(i)} for i in range(len(texts))])\n",
        "\n",
        "query = \"What is the course about?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "\n",
        "chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
        "print(chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)['output_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aexdGsleElg0",
        "outputId": "e7f6697d-730a-48b7-92a7-b7b88d6b0c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The course is about language models and their capabilities, including completing sequences of words or characters. \n",
            "SOURCES: 108, 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "?Chroma.from_texts"
      ],
      "metadata": {
        "id": "p6eFl4TnFnYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# docsearch.similarity_search_with_score(query)"
      ],
      "metadata": {
        "id": "jvViKkHUGNlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Log, Track, Debug Prompts with Comet"
      ],
      "metadata": {
        "id": "31cHzfzZNVuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install comet-llm --quiet"
      ],
      "metadata": {
        "id": "UltYbu6AHOIx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import IPython\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import comet_llm\n",
        "import urllib"
      ],
      "metadata": {
        "id": "WzbTUqePN0FP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# API Configuration\n",
        "openai.api_key ="
      ],
      "metadata": {
        "id": "2xje1mbMOR05"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "\n",
        "# print markdown\n",
        "def print_markdown(text):\n",
        "    \"\"\"Prints text as markdown\"\"\"\n",
        "    IPython.display.display(IPython.display.Markdown(text))\n",
        "\n",
        "# load validation data from GitHub\n",
        "f = urllib.request.urlopen(\"https://raw.githubusercontent.com/comet-ml/comet-llmops/main/data/article-tags.json\")\n",
        "val_data = json.load(f)\n",
        "\n",
        "# load few shot data from GitHub\n",
        "f = urllib.request.urlopen(\"https://raw.githubusercontent.com/comet-ml/comet-llmops/main/data/few_shot.json\")\n",
        "few_shot_data = json.load(f)"
      ],
      "metadata": {
        "id": "zwJr1Ty2OEYM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to get responses given a prompt template (e.g., zero-shot or few-shot) and input data\n",
        "\n",
        "def get_predictions(prompt_template, inputs):\n",
        "\n",
        "  responses = []\n",
        "\n",
        "  for i in range(len(inputs)):\n",
        "    messages = [\n",
        "        {\n",
        "            'role': 'system',\n",
        "            'content': prompt_template.format(input=inputs[i])\n",
        "        }\n",
        "    ]\n",
        "    response = get_response(messages)\n",
        "    responses.append(response)\n",
        "\n",
        "  return responses"
      ],
      "metadata": {
        "id": "rw4TyRdNOQGN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Few-shot\n",
        "\n",
        "# define a template\n",
        "def get_few_shot_template(few_shot_prefix, few_shot_suffix, few_shot_examples):\n",
        "    return few_shot_prefix + \"\\n\\n\" + \"\\n\".join([ \"Abstract: \"+ ex[\"abstract\"] + \"\\n\" + \"Tags: \" + str(ex[\"tags\"]) + \"\\n\" for ex in few_shot_examples]) + \"\\n\\n\" + few_shot_suffix\n",
        "\n",
        "# function to sample few shot data\n",
        "def random_sample_data (data, n):\n",
        "    return np.random.choice(few_shot_data, n, replace=False)\n",
        "\n",
        "# the few-shot prefix and suffix\n",
        "few_shot_prefix = \"\"\"Your task is to extract model names from machine learning paper abstracts. Your response is an an array of the model names in the format [\\\"model_name\\\"]. If you don't find model names in the abstract or you are not sure, return [\\\"NA\\\"]\"\"\"\n",
        "few_shot_suffix = \"\"\"Abstract: {input}\\nTags:\"\"\"\n",
        "\n",
        "# load 3 samples from few shot data\n",
        "few_shot_template = get_few_shot_template(\n",
        "    few_shot_prefix,\n",
        "    few_shot_suffix,\n",
        "    random_sample_data(few_shot_data, 3)\n",
        "    )"
      ],
      "metadata": {
        "id": "TCp2ibImO-1A"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(few_shot_template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28xgfuwWPQXM",
        "outputId": "c57a117c-0e30-41ef-c381-e0b887877da6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your task is to extract model names from machine learning paper abstracts. Your response is an an array of the model names in the format [\"model_name\"]. If you don't find model names in the abstract or you are not sure, return [\"NA\"]\n",
            "\n",
            "Abstract: The rapid advancement of conversational and chat-based language models has led to remarkable progress in complex task-solving. However, their success heavily relies on human input to guide the conversation, which can be challenging and time-consuming. This paper explores the potential of building scalable techniques to facilitate autonomous cooperation among communicative agents and provide insight into their \"cognitive\" processes. To address the challenges of achieving autonomous cooperation, we propose a novel communicative agent framework named role-playing. Our approach involves using inception prompting to guide chat agents toward task completion while maintaining consistency with human intentions. We showcase how role-playing can be used to generate conversational data for studying the behaviors and capabilities of chat agents, providing a valuable resource for investigating conversational language models. Our contributions include introducing a novel communicative agent framework, offering a scalable approach for studying the cooperative behaviors and capabilities of multi-agent systems, and open-sourcing our library to support research on communicative agents and beyond. The GitHub repository of this project is made publicly available on:\n",
            "Tags: ['NA']\n",
            "\n",
            "Abstract: Children's drawings have a wonderful inventiveness, creativity, and variety to them. We present a system that automatically animates children's drawings of the human figure, is robust to the variance inherent in these depictions, and is simple and straightforward enough for anyone to use. We demonstrate the value and broad appeal of our approach by building and releasing the Animated Drawings Demo, a freely available public website that has been used by millions of people around the world. We present a set of experiments exploring the amount of training data needed for fine-tuning, as well as a perceptual study demonstrating the appeal of a novel twisted perspective retargeting technique. Finally, we introduce the Amateur Drawings Dataset, a first-of-its-kind annotated dataset, collected via the public demo, containing over 178,000 amateur drawings and corresponding user-accepted character bounding boxes, segmentation masks, and joint location annotations.\n",
            "Tags: ['NA']\n",
            "\n",
            "Abstract: Recently, the instruction-tuning of large language models is a crucial area of research in the field of natural language processing. Due to resource and cost limitations, several researchers have employed parameter-efficient tuning techniques, such as LoRA, for instruction tuning, and have obtained encouraging results In comparison to full-parameter fine-tuning, LoRA-based tuning demonstrates salient benefits in terms of training costs. In this study, we undertook experimental comparisons between full-parameter fine-tuning and LoRA-based tuning methods, utilizing LLaMA as the base model. The experimental results show that the selection of the foundational model, training dataset scale, learnable parameter quantity, and model training cost are all important factors. We hope that the experimental conclusions of this paper can provide inspiration for training large language models, especially in the field of Chinese, and help researchers find a better trade-off strategy between training cost and model performance. To facilitate the reproduction of the paper's results, the dataset, model and code will be released.\n",
            "Tags: ['LLaMA']\n",
            "\n",
            "\n",
            "Abstract: {input}\n",
            "Tags:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero-shot\n",
        "\n",
        "# define template\n",
        "zero_shot_template = \"\"\"\n",
        "Your task is extract model names from machine learning paper abstracts. Your response is an an array of the model names in the format [\\\"model_name\\\"]. If you don't find model names in the abstract or you are not sure, return [\\\"NA\\\"]\n",
        "\n",
        "Abstract: {input}\n",
        "Tags:\n",
        "\"\"\"\n",
        "\n",
        "print(zero_shot_template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHMOV2ARPT92",
        "outputId": "35013a87-2fb4-4a05-fe4b-1d52a957ff5e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Your task is extract model names from machine learning paper abstracts. Your response is an an array of the model names in the format [\"model_name\"]. If you don't find model names in the abstract or you are not sure, return [\"NA\"]\n",
            "\n",
            "Abstract: {input}\n",
            "Tags:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions\n",
        "\n",
        "abstracts = [val_data[i][\"abstract\"] for i in range(len(val_data))]\n",
        "few_shot_predictions = get_predictions(few_shot_template, abstracts)\n",
        "zero_shot_predictions = get_predictions(zero_shot_template, abstracts)\n",
        "expected_tags = [str(val_data[i][\"tags\"]) for i in range(len(val_data))]"
      ],
      "metadata": {
        "id": "I3p0lygkPh3y"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Few shot predictions\")\n",
        "print(few_shot_predictions)\n",
        "print(\"\\n\\nZero shot predictions\")\n",
        "print(zero_shot_predictions)\n",
        "print(\"\\n\\nExpected tags\")\n",
        "print(expected_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcla-0_sPlWX",
        "outputId": "003b73bd-427e-4ed8-fbd1-7127a022b5a5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few shot predictions\n",
            "['[\"LLaMA\", \"WizardLM\"]', '[\"LLaMA\", \"FLAN-T5\"]', '[\"role-playing\", \"LoRA\", \"LLaMA\"]', '[\"LLaMA\", \"PAXQA\"]', '[\"ChatGPT\"]', '[\"LLaMA\", \"ViT\", \"OpenCLIP\"]', '[\"LLaMA\", \"Segment-Anything Model (SAM)\", \"Inpaint Anything (IA)\"]', '[\"LLaMA\", \"Anything-3D\"]', '[\"Chameleon\"]', '[\"LLaMA\"]']\n",
            "\n",
            "\n",
            "Zero shot predictions\n",
            "['[\"WizardLM\", \"ChatGPT\"]', '[\"FLAN-T5\"]', '[\"NA\"]', '[\"PAXQA\"]', '[\"ChatGPT\"]', '[\"ViT\", \"OpenCLIP\"]', '[\"Segment-Anything Model\", \"Inpaint Anything\", \"Stable Diffusion\"]', '[\"Anything-3D\", \"BLIP\", \"Segment-Anything\"]', '[\"Chameleon\", \"GPT-4\", \"ChatGPT\"]', '[\"NA\"]']\n",
            "\n",
            "\n",
            "Expected tags\n",
            "[\"['LLaMA', 'ChatGPT', 'WizardLM']\", \"['FLAN-T5', 'FLAN']\", \"['NA']\", \"['PAXQA']\", \"['ChatGPT']\", \"['OpenCLIP', 'ViT']\", \"['SAM', 'IA']\", \"['Anything-3D', 'BLIP', 'Segment-Anything']\", \"['Chameleon', 'GPT-4', 'ChatGPT']\", \"['NA']\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# log prompt + results along with ground truth for comparison\n",
        "# Note that we are logging both the few-shot and zero-shot results, along with\n",
        "# all metadatas and tags\n",
        "\n",
        "# Comet comparison\n",
        "COMET_API_KEY =\n",
        "COMET_WORKSPACE = \"biokinducsd\""
      ],
      "metadata": {
        "id": "jzvXj3n6QLTd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize comet project\n",
        "comet_llm.init(COMET_API_KEY, COMET_WORKSPACE, project=\"ml-paper-tagger-prompts\")\n",
        "\n",
        "# log the predictions\n",
        "for i in range(len(expected_tags)):\n",
        "\n",
        "    # log the few-shot predictions\n",
        "    comet_llm.log_prompt(\n",
        "        prompt=few_shot_template.format(input=abstracts[i]),\n",
        "        prompt_template=few_shot_template,\n",
        "        output=few_shot_predictions[i],\n",
        "        tags = [\"gpt-4o\", \"few-shot\"],\n",
        "        metadata = {\n",
        "            \"expected_tags\": expected_tags[i],\n",
        "            \"abstract\": abstracts[i],\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # log the zero-shot predictions\n",
        "    comet_llm.log_prompt(\n",
        "        prompt=zero_shot_template.format(input=abstracts[i]),\n",
        "        prompt_template=zero_shot_template,\n",
        "        output=zero_shot_predictions[i],\n",
        "        tags = [\"gpt-4o\", \"zero-shot\"],\n",
        "        metadata = {\n",
        "            \"expected_tags\": expected_tags[i],\n",
        "            \"abstract\": abstracts[i],\n",
        "        }\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfRIieDPRkRI",
        "outputId": "7a214242-fe7c-421c-9467-db5c926f412e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt logged to https://www.comet.com/biokinducsd/ml-paper-tagger-prompts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:comet_llm.summary:Prompt logged to https://www.comet.com/biokinducsd/ml-paper-tagger-prompts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DzwKCbJ9R-pC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}